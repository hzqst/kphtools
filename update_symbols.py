#!/usr/bin/env python3
"""
Symbol Update Script for KPH Dynamic Data

Updates field offsets in kphdyn.xml by parsing PDB files using llvm-pdbutil.

Usage:
    python update_symbols.py -xml kphdyn.xml -symboldir C:/Symbols -json kphdyn.json

Requirements:
    - llvm-pdbutil must be available in system PATH
"""

import json
import os
import re
import argparse
import subprocess
import sys
import xml.etree.ElementTree as ET


# XML header with copyright notice
XML_HEADER = """<?xml version="1.0" encoding="utf-8"?>
<!--
Copyright (c) 2022 Winsider Seminars & Solutions, Inc.  All rights reserved.

This file is part of System Informer.

THIS IS AN AUTOGENERATED FILE, DO NOT MODIFY
    -->
"""


def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Updates field offsets in kphdyn.xml by parsing PDB files using llvm-pdbutil"
    )
    parser.add_argument(
        "-xml",
        required=True,
        help="Path to the XML file (e.g., kphdyn.xml)"
    )
    parser.add_argument(
        "-symboldir",
        required=True,
        help="Directory containing symbol files"
    )
    parser.add_argument(
        "-json",
        required=True,
        help="Path to the JSON config file (e.g., kphdyn.json)"
    )
    parser.add_argument(
        "-debug",
        action="store_true",
        help="Enable debug logging for symbol parsing"
    )

    args = parser.parse_args()

    if not args.xml:
        parser.error("-xml cannot be empty")
    if not args.symboldir:
        parser.error("-symboldir cannot be empty")
    if not args.json:
        parser.error("-json cannot be empty")

    return args


def load_json_config(json_path):
    """
    Load JSON configuration file.

    Args:
        json_path: Path to JSON file

    Returns:
        Tuple of (file_list, symbols_list)
        - file_list: List of file names to match (e.g., ["ntoskrnl.exe", "ntkrla57.exe"])
        - symbols_list: List of symbol dicts with "name" and "symbol" keys
    """
    if not os.path.exists(json_path):
        print(f"Error: JSON file not found: {json_path}")
        sys.exit(1)

    with open(json_path, "r", encoding="utf-8") as f:
        config = json.load(f)

    if not isinstance(config, list) or len(config) == 0:
        print("Error: JSON config must be a non-empty array")
        sys.exit(1)

    # Use the first entry
    entry = config[0]

    file_list = entry.get("file", [])
    symbols_list = entry.get("symbols", [])

    if not file_list:
        print("Error: JSON config missing 'file' array")
        sys.exit(1)

    if not symbols_list:
        print("Error: JSON config missing 'symbols' array")
        sys.exit(1)

    # Validate symbols
    for sym in symbols_list:
        if "name" not in sym or "symbol" not in sym:
            print(f"Error: Each symbol must have 'name' and 'symbol' keys: {sym}")
            sys.exit(1)

    return file_list, symbols_list


def parse_symbol(symbol_str):
    """
    Parse a single symbol string into structure name and member name.

    Args:
        symbol_str: Symbol string like "_EPROCESS->SectionObject" or "_ALPC_PORT->u1.State"

    Returns:
        Tuple of (struct_name, member_name)
    """
    if "->" not in symbol_str:
        print(f"Error: Invalid symbol format '{symbol_str}'. Expected format: STRUCT->Member")
        sys.exit(1)

    parts = symbol_str.split("->", 1)
    if len(parts) != 2:
        print(f"Error: Invalid symbol format '{symbol_str}'. Expected format: STRUCT->Member")
        sys.exit(1)

    struct_name = parts[0].strip()
    member_name = parts[1].strip()

    # Add underscore prefix if not present (Windows kernel structures use _EPROCESS format)
    if not struct_name.startswith("_"):
        struct_name = "_" + struct_name

    return struct_name, member_name


def parse_symbol_with_fallback(symbol_str):
    """
    Parse symbol string that may contain fallback alternatives.

    Args:
        symbol_str: Symbol string, optionally with comma-separated fallbacks
                   e.g., "_SECTION->u1.ControlArea,_SECTION_OBJECT->Segment"

    Returns:
        List of (struct_name, member_name) tuples
    """
    alternatives = [s.strip() for s in symbol_str.split(",")]
    return [parse_symbol(alt) for alt in alternatives]


def get_all_entries_for_files(root, file_list):
    """
    Get all <data> elements matching any file in file_list.

    Args:
        root: XML root element
        file_list: List of file names to match

    Returns:
        List of matching data elements
    """
    entries = []
    for data_elem in root.findall("data"):
        file_name = data_elem.get("file")
        if file_name in file_list:
            entries.append(data_elem)
    return entries


def collect_existing_fields(root):
    """
    Collect all existing <fields> elements.

    Args:
        root: XML root element

    Returns:
        Dict mapping fields ID (int) to dict of {name: offset_int}
    """
    fields_map = {}
    for fields_elem in root.findall("fields"):
        fields_id = fields_elem.get("id")
        if fields_id is None:
            continue

        try:
            fields_id_int = int(fields_id)
        except ValueError:
            continue

        field_dict = {}
        for field_elem in fields_elem.findall("field"):
            name = field_elem.get("name")
            value = field_elem.get("value")
            if name and value:
                # Parse hex value like "0x0418"
                try:
                    offset = int(value, 16)
                    field_dict[name] = offset
                except ValueError:
                    pass

        fields_map[fields_id_int] = field_dict

    return fields_map


def get_pdb_path(symboldir, arch, version):
    """
    Build the path to the PDB file.

    Args:
        symboldir: Base symbol directory
        arch: Architecture (amd64, arm64, etc.)
        version: Windows version string

    Returns:
        Path to the PDB file
    """
    symbol_subdir = os.path.join(symboldir, arch, f"ntoskrnl.exe.{version}")
    pdb_path = os.path.join(symbol_subdir, "ntkrnlmp.pdb")
    return pdb_path


def run_llvm_pdbutil(pdb_path):
    """
    Run llvm-pdbutil to dump type information.

    Args:
        pdb_path: Path to the PDB file

    Returns:
        Output string, or None on failure
    """
    if not os.path.exists(pdb_path):
        return None

    try:
        result = subprocess.run(
            ["llvm-pdbutil", "dump", "-types", pdb_path],
            capture_output=True,
            text=True,
            timeout=300  # 5 minute timeout
        )

        if result.returncode != 0:
            print(f"  llvm-pdbutil failed: {result.stderr}")
            return None

        return result.stdout

    except FileNotFoundError:
        print("Error: llvm-pdbutil not found in PATH")
        print("Please install LLVM tools and ensure llvm-pdbutil is in your PATH")
        sys.exit(1)
    except subprocess.TimeoutExpired:
        print(f"  Timeout while parsing PDB: {pdb_path}")
        return None
    except Exception as e:
        print(f"  Error running llvm-pdbutil: {e}")
        return None


def parse_llvm_pdbutil_output(output, struct_name, member_name, debug=False):
    """
    Parse llvm-pdbutil dump output to find member offset.

    Handles nested members like "u1.State" by finding the first part (u1)
    in the parent struct, then looking for the nested member in the union/struct type.

    Args:
        output: llvm-pdbutil output string
        struct_name: Structure name to find (e.g., _EPROCESS)
        member_name: Member name to find offset for (e.g., Protection or u1.State)
        debug: Enable debug logging

    Returns:
        Offset as integer, or None if not found
    """
    lines = output.split('\n')

    # Handle nested members (e.g., u1.State)
    if '.' in member_name:
        parts = member_name.split('.', 1)
        parent_member = parts[0]
        nested_member = parts[1]

        if debug:
            print(f"    [DEBUG] Nested member: {struct_name}->{parent_member}.{nested_member}")

        # First, find the parent member's offset and type
        parent_offset = find_member_offset(lines, struct_name, parent_member, debug)
        if parent_offset is None:
            if debug:
                print(f"    [DEBUG] Parent member '{parent_member}' not found in '{struct_name}'")
            return None

        if debug:
            print(f"    [DEBUG] Parent offset: {parent_offset} (0x{parent_offset:x})")

        # Find the type of the parent member to get nested member offset
        parent_type_name, parent_type_id = find_member_type(lines, struct_name, parent_member, debug)

        if parent_type_id is None:
            if debug:
                print(f"    [DEBUG] Parent type ID not found, trying direct member search")
            # Try to find nested member by searching for it as a direct member
            # This handles anonymous unions/structs
            nested_offset = find_member_offset(lines, struct_name, nested_member, debug)
            if nested_offset is not None:
                if debug:
                    print(f"    [DEBUG] Found nested member as direct member: offset={nested_offset}")
                return nested_offset
            if debug:
                print(f"    [DEBUG] Nested member '{nested_member}' not found as direct member")
            return None

        if debug:
            print(f"    [DEBUG] Parent type: {parent_type_name} (ID: {parent_type_id})")

        # Get the offset of nested member within the parent type using type ID
        nested_offset = find_member_offset_by_type_id(lines, parent_type_id, nested_member, debug)
        if nested_offset is None:
            if debug:
                print(f"    [DEBUG] Nested member '{nested_member}' not found in type {parent_type_id}")
            return None

        if debug:
            print(f"    [DEBUG] Nested offset: {nested_offset}, total: {parent_offset + nested_offset}")

        return parent_offset + nested_offset

    # Simple member (no nesting)
    return find_member_offset(lines, struct_name, member_name, debug)


def find_member_offset(lines, struct_name, member_name, debug=False):
    """
    Find the offset of a member within a structure.

    Args:
        lines: List of output lines
        struct_name: Structure name
        member_name: Member name
        debug: Enable debug logging

    Returns:
        Offset as integer, or None if not found
    """
    # Step 1: Find the structure definition and get its field list ID
    field_list_id = None

    # Try LF_STRUCTURE first
    for i, line in enumerate(lines):
        if "LF_STRUCTURE" in line and f"`{struct_name}`" in line:
            if debug:
                print(f"    [DEBUG] Found LF_STRUCTURE for '{struct_name}' at line {i}")
            for j in range(i + 1, min(i + 10, len(lines))):
                next_line = lines[j]
                if "forward ref" in next_line:
                    if debug:
                        print(f"    [DEBUG] Skipping forward reference")
                    break
                field_list_match = re.search(r'field list:\s*(0x[0-9a-fA-F]+)', next_line)
                if field_list_match:
                    field_list_id = field_list_match.group(1)
                    if debug:
                        print(f"    [DEBUG] Found field list ID: {field_list_id}")
                    break

            if field_list_id:
                break

    # Also check for LF_UNION
    if not field_list_id:
        for i, line in enumerate(lines):
            if "LF_UNION" in line and f"`{struct_name}`" in line:
                if debug:
                    print(f"    [DEBUG] Found LF_UNION for '{struct_name}' at line {i}")
                for j in range(i + 1, min(i + 10, len(lines))):
                    next_line = lines[j]
                    if "forward ref" in next_line:
                        if debug:
                            print(f"    [DEBUG] Skipping forward reference")
                        break
                    field_list_match = re.search(r'field list:\s*(0x[0-9a-fA-F]+)', next_line)
                    if field_list_match:
                        field_list_id = field_list_match.group(1)
                        if debug:
                            print(f"    [DEBUG] Found field list ID: {field_list_id}")
                        break

                if field_list_id:
                    break

    # Try LF_CLASS as fallback
    if not field_list_id:
        for i, line in enumerate(lines):
            if "LF_CLASS" in line and f"`{struct_name}`" in line:
                if debug:
                    print(f"    [DEBUG] Found LF_CLASS for '{struct_name}' at line {i}")
                for j in range(i + 1, min(i + 10, len(lines))):
                    next_line = lines[j]
                    if "forward ref" in next_line:
                        if debug:
                            print(f"    [DEBUG] Skipping forward reference")
                        break
                    field_list_match = re.search(r'field list:\s*(0x[0-9a-fA-F]+)', next_line)
                    if field_list_match:
                        field_list_id = field_list_match.group(1)
                        if debug:
                            print(f"    [DEBUG] Found field list ID: {field_list_id}")
                        break

                if field_list_id:
                    break

    if not field_list_id:
        if debug:
            print(f"    [DEBUG] No field list ID found for '{struct_name}'")
            # Try to find any mention of the struct name for debugging
            for i, line in enumerate(lines):
                if struct_name in line:
                    print(f"    [DEBUG] Found '{struct_name}' mention at line {i}: {line.strip()[:100]}")
                    if i < 5:  # Only show first few matches
                        continue
                    break
        return None

    # Step 2: Find the LF_FIELDLIST with this ID and search for the member
    in_field_list = False

    for line in lines:
        if f"{field_list_id} | LF_FIELDLIST" in line:
            in_field_list = True
            if debug:
                print(f"    [DEBUG] Entered field list {field_list_id}")
            continue

        if in_field_list and re.match(r'\s*0x[0-9a-fA-F]+\s*\|\s*LF_', line):
            in_field_list = False
            continue

        if in_field_list:
            match = re.search(
                rf'LF_MEMBER\s*\[name\s*=\s*`{re.escape(member_name)}`.*offset\s*=\s*(\d+)',
                line
            )
            if match:
                offset = int(match.group(1))
                if debug:
                    print(f"    [DEBUG] Found member '{member_name}' with offset {offset}")
                return offset

    if debug:
        print(f"    [DEBUG] Member '{member_name}' not found in field list {field_list_id}")
    return None


def find_member_type(lines, struct_name, member_name, debug=False):
    """
    Find the type of a member within a structure.

    Args:
        lines: List of output lines
        struct_name: Structure name
        member_name: Member name
        debug: Enable debug logging

    Returns:
        Tuple of (type_name, type_id) or (None, None) if not found
    """
    # Find the structure's field list ID
    field_list_id = None

    for i, line in enumerate(lines):
        if "LF_STRUCTURE" in line and f"`{struct_name}`" in line:
            for j in range(i + 1, min(i + 10, len(lines))):
                next_line = lines[j]
                if "forward ref" in next_line:
                    break
                field_list_match = re.search(r'field list:\s*(0x[0-9a-fA-F]+)', next_line)
                if field_list_match:
                    field_list_id = field_list_match.group(1)
                    break

            if field_list_id:
                break

    if not field_list_id:
        if debug:
            print(f"    [DEBUG] find_member_type: No field list for '{struct_name}'")
        return None, None

    # Find the member and extract its type
    in_field_list = False
    type_id = None

    for line in lines:
        if f"{field_list_id} | LF_FIELDLIST" in line:
            in_field_list = True
            continue

        if in_field_list and re.match(r'\s*0x[0-9a-fA-F]+\s*\|\s*LF_', line):
            in_field_list = False
            continue

        if in_field_list:
            match = re.search(
                rf'LF_MEMBER\s*\[name\s*=\s*`{re.escape(member_name)}`.*Type\s*=\s*(0x[0-9a-fA-F]+)',
                line
            )
            if match:
                type_id = match.group(1)
                if debug:
                    print(f"    [DEBUG] find_member_type: Found type ID {type_id} for '{member_name}'")
                break

    if not type_id:
        if debug:
            print(f"    [DEBUG] find_member_type: No type ID found for '{member_name}'")
        return None, None

    # Find the type definition to get its name
    for i, line in enumerate(lines):
        if f"{type_id} | LF_" in line:
            # Extract type name from the line
            name_match = re.search(r'`([^`]+)`', line)
            if name_match:
                type_name = name_match.group(1)
                if debug:
                    print(f"    [DEBUG] find_member_type: Type {type_id} is '{type_name}'")
                return type_name, type_id
            else:
                if debug:
                    print(f"    [DEBUG] find_member_type: Type {type_id} has no name, line: {line.strip()}")
                return None, type_id

    if debug:
        print(f"    [DEBUG] find_member_type: Type definition for {type_id} not found")
    return None, None


def find_member_offset_by_type_id(lines, type_id, member_name, debug=False):
    """
    Find the offset of a member within a structure/union identified by type ID.

    Args:
        lines: List of output lines
        type_id: Type ID (e.g., 0x1B3D)
        member_name: Member name
        debug: Enable debug logging

    Returns:
        Offset as integer, or None if not found
    """
    # Find the type definition and get its field list ID
    field_list_id = None

    for i, line in enumerate(lines):
        if f"{type_id} | LF_" in line and ("LF_STRUCTURE" in line or "LF_UNION" in line):
            if debug:
                print(f"    [DEBUG] Found type {type_id} at line {i}: {line.strip()[:80]}")
            for j in range(i + 1, min(i + 10, len(lines))):
                next_line = lines[j]
                if "forward ref" in next_line:
                    if debug:
                        print(f"    [DEBUG] Skipping forward reference for {type_id}")
                    break
                field_list_match = re.search(r'field list:\s*(0x[0-9a-fA-F]+)', next_line)
                if field_list_match:
                    field_list_id = field_list_match.group(1)
                    if debug:
                        print(f"    [DEBUG] Type {type_id} has field list ID: {field_list_id}")
                    break

            if field_list_id:
                break

    if not field_list_id:
        if debug:
            print(f"    [DEBUG] No field list ID found for type {type_id}")
        return None

    # Find the LF_FIELDLIST with this ID and search for the member
    in_field_list = False

    for line in lines:
        if f"{field_list_id} | LF_FIELDLIST" in line:
            in_field_list = True
            if debug:
                print(f"    [DEBUG] Entered field list {field_list_id} for type {type_id}")
            continue

        if in_field_list and re.match(r'\s*0x[0-9a-fA-F]+\s*\|\s*LF_', line):
            in_field_list = False
            continue

        if in_field_list:
            match = re.search(
                rf'LF_MEMBER\s*\[name\s*=\s*`{re.escape(member_name)}`.*offset\s*=\s*(\d+)',
                line
            )
            if match:
                offset = int(match.group(1))
                if debug:
                    print(f"    [DEBUG] Found member '{member_name}' in type {type_id} with offset {offset}")
                return offset

    if debug:
        print(f"    [DEBUG] Member '{member_name}' not found in type {type_id} field list {field_list_id}")
    return None


def parse_pdb_all_symbols(pdb_path, symbols_list, debug=False):
    """
    Parse PDB file to get offsets for all symbols.

    Args:
        pdb_path: Path to the PDB file
        symbols_list: List of symbol dicts with "name" and "symbol" keys
                      Symbol can contain comma-separated fallbacks
        debug: Enable debug logging

    Returns:
        Dict mapping symbol name to offset (0xffffffff if symbol not found)
    """
    output = run_llvm_pdbutil(pdb_path)
    if output is None:
        return None

    offsets = {}
    for sym in symbols_list:
        name = sym["name"]
        symbol_str = sym["symbol"]

        # Parse symbol with fallback support
        alternatives = parse_symbol_with_fallback(symbol_str)

        if debug:
            if len(alternatives) > 1:
                print(f"    [DEBUG] Parsing symbol: {symbol_str} (with {len(alternatives)} alternatives)")
            else:
                struct_name, member_name = alternatives[0]
                print(f"    [DEBUG] Parsing symbol: {symbol_str} -> {struct_name}->{member_name}")

        offset = None
        used_alternative = None
        for struct_name, member_name in alternatives:
            offset = parse_llvm_pdbutil_output(output, struct_name, member_name, debug)
            if offset is not None:
                used_alternative = f"{struct_name}->{member_name}"
                break

        if offset is None:
            print(f"  Warning: Symbol not found: {symbol_str}, using 0xffffffff")
            offset = 0xffffffff

        if debug:
            if len(alternatives) > 1 and used_alternative:
                print(f"    [DEBUG] Result: {name} = 0x{offset:04x} (using {used_alternative})")
            else:
                print(f"    [DEBUG] Result: {name} = 0x{offset:04x}")

        offsets[name] = offset

    return offsets


def find_matching_fields_id(existing_fields, new_offsets):
    """
    Find an existing fields ID that matches the new offsets exactly.

    Args:
        existing_fields: Dict mapping fields ID to {name: offset}
        new_offsets: Dict of {name: offset} to match

    Returns:
        Matching fields ID (int), or None if no match
    """
    for fields_id, field_dict in existing_fields.items():
        if field_dict == new_offsets:
            return fields_id
    return None


def allocate_new_fields_id(existing_ids):
    """
    Allocate a new fields ID that doesn't conflict with existing ones.

    Args:
        existing_ids: Set of existing IDs (integers)

    Returns:
        New ID (int)
    """
    if not existing_ids:
        return 1
    return max(existing_ids) + 1


def create_fields_element(root, fields_id, offsets, symbols_list):
    """
    Create a new <fields> element with the given offsets.

    Args:
        root: XML root element
        fields_id: ID for the new fields element
        offsets: Dict of {name: offset}
        symbols_list: List of symbol dicts to preserve order
    """
    fields_elem = ET.SubElement(root, "fields")
    fields_elem.set("id", str(fields_id))

    # Add fields in the order specified in symbols_list
    for sym in symbols_list:
        name = sym["name"]
        if name in offsets:
            field_elem = ET.SubElement(fields_elem, "field")
            field_elem.set("value", f"0x{offsets[name]:04x}")
            field_elem.set("name", name)


def remove_orphan_fields(root, referenced_ids):
    """
    Remove <fields> elements that are not referenced by any <data> entry.

    Args:
        root: XML root element
        referenced_ids: Set of fields IDs that are referenced
    """
    fields_to_remove = []
    for fields_elem in root.findall("fields"):
        fields_id = fields_elem.get("id")
        if fields_id is not None:
            try:
                fields_id_int = int(fields_id)
                if fields_id_int not in referenced_ids:
                    fields_to_remove.append(fields_elem)
            except ValueError:
                pass

    for fields_elem in fields_to_remove:
        root.remove(fields_elem)

    return len(fields_to_remove)


def save_xml_with_header(root, xml_path):
    """
    Save XML with proper header and formatting.

    Args:
        root: XML root element
        xml_path: Path to save the XML file
    """
    # Build the XML content manually to preserve formatting
    lines = [XML_HEADER.rstrip()]
    lines.append("<dyn>")

    # Add data elements first
    for data_elem in root.findall("data"):
        attrs = []
        for attr in ["arch", "version", "file", "hash", "timestamp", "size"]:
            val = data_elem.get(attr)
            if val is not None:
                attrs.append(f'{attr}="{val}"')
        attrs_str = " ".join(attrs)
        text = data_elem.text or ""
        lines.append(f"    <data {attrs_str}>{text}</data>")

    # Add fields elements
    for fields_elem in root.findall("fields"):
        fields_id = fields_elem.get("id")
        lines.append(f'    <fields id="{fields_id}">')

        for field_elem in fields_elem.findall("field"):
            value = field_elem.get("value")
            name = field_elem.get("name")
            lines.append(f'        <field value="{value}" name="{name}"/>')

        lines.append("    </fields>")

    lines.append("</dyn>")
    lines.append("")  # Final newline

    with open(xml_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))


def main():
    """Main entry point."""
    args = parse_args()

    xml_path = args.xml
    symboldir = args.symboldir
    json_path = args.json
    debug = args.debug

    # Validate paths
    if not os.path.exists(xml_path):
        print(f"Error: XML file not found: {xml_path}")
        sys.exit(1)

    if not os.path.exists(symboldir):
        print(f"Error: Symbol directory not found: {symboldir}")
        sys.exit(1)

    # Load JSON config
    print(f"Loading JSON config: {json_path}")
    file_list, symbols_list = load_json_config(json_path)
    print(f"  Files to process: {file_list}")
    print(f"  Symbols to extract: {len(symbols_list)}")

    if debug:
        print(f"  Debug mode: enabled")

    # Parse XML
    print(f"\nParsing XML: {xml_path}")
    tree = ET.parse(xml_path)
    root = tree.getroot()

    # Collect existing fields
    existing_fields = collect_existing_fields(root)
    print(f"  Found {len(existing_fields)} existing fields sections")

    # Get all data entries for the specified files
    data_entries = get_all_entries_for_files(root, file_list)
    print(f"  Found {len(data_entries)} data entries to process")

    if not data_entries:
        print("No data entries found for the specified files.")
        sys.exit(0)

    # Process each data entry
    referenced_ids = set()
    new_fields = {}  # id -> offsets
    pdb_cache = {}  # (arch, version) -> offsets

    success_count = 0
    skip_count = 0
    fail_count = 0

    for i, data_entry in enumerate(data_entries):
        arch = data_entry.get("arch")
        version = data_entry.get("version")
        file_name = data_entry.get("file")

        print(f"\n[{i+1}/{len(data_entries)}] Processing {file_name} {version} ({arch})")

        # Check cache first
        cache_key = (arch, version)
        if cache_key in pdb_cache:
            offsets = pdb_cache[cache_key]
            print(f"  Using cached offsets")
        else:
            # Find and parse PDB
            pdb_path = get_pdb_path(symboldir, arch, version)

            if not os.path.exists(pdb_path):
                print(f"  PDB not found: {pdb_path}")
                skip_count += 1
                continue

            print(f"  Parsing PDB: {pdb_path}")
            offsets = parse_pdb_all_symbols(pdb_path, symbols_list, debug)

            if offsets is None:
                print(f"  Failed to extract all symbols")
                fail_count += 1
                sys.exit(1)  # Exit on symbol not found

            pdb_cache[cache_key] = offsets

        # Find matching fields ID
        fields_id = find_matching_fields_id(existing_fields, offsets)

        if fields_id is None:
            # Check new fields
            for new_id, new_offsets in new_fields.items():
                if new_offsets == offsets:
                    fields_id = new_id
                    break

        if fields_id is None:
            # Allocate new ID
            all_ids = set(existing_fields.keys()) | set(new_fields.keys())
            fields_id = allocate_new_fields_id(all_ids)
            new_fields[fields_id] = offsets
            print(f"  Created new fields id={fields_id}")
        else:
            print(f"  Using existing fields id={fields_id}")

        # Update data entry
        data_entry.text = str(fields_id)
        referenced_ids.add(fields_id)
        success_count += 1

    # Add new fields elements to the XML
    for fields_id, offsets in sorted(new_fields.items()):
        create_fields_element(root, fields_id, offsets, symbols_list)

    # Remove orphan fields
    removed_count = remove_orphan_fields(root, referenced_ids)
    if removed_count > 0:
        print(f"\nRemoved {removed_count} orphan fields sections")

    # Save XML
    print(f"\nSaving XML to: {xml_path}")
    save_xml_with_header(root, xml_path)

    # Summary
    print(f"\n{'='*50}")
    print(f"Summary: {success_count} updated, {skip_count} skipped, {fail_count} failed")
    print(f"Total fields sections: {len(referenced_ids)}")

    if fail_count > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
